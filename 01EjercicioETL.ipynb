{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f12b790c-38f9-48c3-8ad5-63c5a7a8cf21",
   "metadata": {},
   "source": [
    "### Paso 1: **Crear un nuevo archivo Python en Jupyter Lab**\n",
    "En la pantalla principal de Jupyter Lab, haz clic en \"Python File\" en la sección inferior de la ventana.\n",
    "Esto abrirá un nuevo archivo en blanco donde podrás escribir el código para tu ejercicio de ETL.\n",
    "### Paso 2: **Importar las bibliotecas necesarias**\n",
    "Al inicio de tu archivo Python, importa las bibliotecas necesarias de PySpark. Esto es importante para poder trabajar con Spark y manejar los datos de forma eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54323a4d-7653-442f-8080-6458d7bf33df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbb92bf-eb68-448d-b8a7-5cfcbf668356",
   "metadata": {},
   "source": [
    "### Explicación:\n",
    "\n",
    "- SparkSession es necesario para crear una sesión de Spark y poder usar PySpark.\n",
    "- col y when son funciones de PySpark que se utilizan para manipular columnas de los DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dc5faa-9240-424e-b890-c3cb8d077963",
   "metadata": {},
   "source": [
    "### Paso 3: **Crear la sesión de Spark**\n",
    "Ahora, crea la sesión de Spark. Esto es esencial para cualquier operación de PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb19209-26de-4410-a5c0-a6521ff8c724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la sesión de Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Primer ejercicio ETL\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8f46ea-c92e-4241-bd94-eac8bbe93c93",
   "metadata": {},
   "source": [
    "### Explicación:\n",
    "\n",
    "- SparkSession.builder.appName(\"Primer ejercicio ETL\") crea una nueva sesión de Spark con el nombre \"Primer ejercicio ETL\".\n",
    "- .getOrCreate() permite crear la sesión si no existe una o reutilizarla si ya está activa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469a3947-c146-4691-b462-82faa1e2bdce",
   "metadata": {},
   "source": [
    "### Paso 4: **Cargar los datos (Extract)**\n",
    "Vamos a cargar un archivo de datos (puede ser un CSV, JSON, etc.) en un DataFrame de PySpark. Para este ejemplo, supongamos que tenemos un archivo CSV con datos de ventas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311401e8-903d-40a9-bd39-47506683eada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos desde un archivo CSV\n",
    "df = spark.read.option(\"header\", \"true\").csv(\"/ruta/a/tu/archivo.csv\")\n",
    "\n",
    "# Mostrar los primeros 5 registros para verificar\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d2b7d9-89e4-4b4b-bdb9-0f0afdf6c917",
   "metadata": {},
   "source": [
    "### Explicación:\n",
    "\n",
    "- spark.read.option(\"header\", \"true\").csv(\"/ruta/a/tu/archivo.csv\") carga un archivo CSV en un DataFrame, especificando que la primera fila contiene los encabezados.\n",
    "- df.show(5) muestra las primeras 5 filas del DataFrame para asegurarse de que los datos se cargaron correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7e67f3-2898-4b97-993c-f9e50ae206e6",
   "metadata": {},
   "source": [
    "### Paso 5: **Transformación de los datos (Transform)**\n",
    "Ahora vamos a realizar algunas transformaciones en los datos. Supongamos que tenemos una columna \"Precio\" y queremos aplicar un descuento del 10% a todas las filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ba021-3f3b-4f1b-baba-102883dcf441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar los datos: aplicar un descuento del 10% en la columna \"Precio\"\n",
    "df_transformado = df.withColumn(\"Precio con descuento\", col(\"Precio\") * 0.9)\n",
    "\n",
    "# Mostrar los primeros 5 registros después de la transformación\n",
    "df_transformado.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b8becb-dfd0-4bf5-bbb4-ed69007454e9",
   "metadata": {},
   "source": [
    "### Explicación:\n",
    "\n",
    "- df.withColumn(\"Precio con descuento\", col(\"Precio\") * 0.9) crea una nueva columna en el DataFrame que contiene el precio con un descuento del 10%.\n",
    "- df_transformado.show(5) muestra los primeros 5 registros después de aplicar la transformación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3372be40-3a6d-4908-beed-515468380603",
   "metadata": {},
   "source": [
    "### Paso 6: **Cargar los datos transformados (Load)**\n",
    "Finalmente, vamos a guardar los datos transformados en un nuevo archivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7cd4b4-6551-4a22-bd88-aae59ae338f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los datos transformados en un archivo CSV\n",
    "df_transformado.write.option(\"header\", \"true\").csv(\"/ruta/a/guardar/archivo_transformado.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5403a772-97c4-4447-9074-f85f384aa10c",
   "metadata": {},
   "source": [
    "### Explicación:\n",
    "\n",
    "- df_transformado.write.option(\"header\", \"true\").csv(\"/ruta/a/guardar/archivo_transformado.csv\") guarda el DataFrame transformado en un nuevo archivo CSV, con los encabezados incluidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272019b1-b6ee-4c7d-843f-32b8109dcea4",
   "metadata": {},
   "source": [
    "### Paso 7: **Ejecutar el código**\n",
    "- 1. Una vez que hayas escrito todo el código, presiona Shift + Enter para ejecutar las celdas de Jupyter.\n",
    "- 2. Jupyter Lab ejecutará el código y podrás ver los resultados en las celdas de salida, como los datos cargados, transformados y la confirmación de que los datos se han guardado correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c221ba88-b6fd-4e72-9f96-b0530634e617",
   "metadata": {},
   "source": [
    "### Ejemplo completo de código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be76865-b075-4757-9b11-5af78cd2e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Importar las bibliotecas necesarias\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Paso 2: Crear la sesión de Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Primer ejercicio ETL\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Paso 3: Cargar los datos (Extract)\n",
    "df = spark.read.option(\"header\", \"true\").csv(\"/ruta/a/tu/archivo.csv\")\n",
    "df.show(5)\n",
    "\n",
    "# Paso 4: Transformación de los datos (Transform)\n",
    "df_transformado = df.withColumn(\"Precio con descuento\", col(\"Precio\") * 0.9)\n",
    "df_transformado.show(5)\n",
    "\n",
    "# Paso 5: Cargar los datos transformados (Load)\n",
    "df_transformado.write.option(\"header\", \"true\").csv(\"/ruta/a/guardar/archivo_transformado.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24c1036-19f3-4d9b-ab04-908f21cdf187",
   "metadata": {},
   "source": [
    "## Resumen:\n",
    "\n",
    "- **Extract**: Cargamos los datos desde un archivo CSV.\n",
    "- **Transform**: Aplicamos una transformación, en este caso un descuento en los precios.\n",
    "- **Load**: Guardamos los datos transformados en un nuevo archivo CSV.\n",
    "\n",
    "¡Listo! Ahora tienes un ejercicio completo de ETL usando PySpark en Jupyter Lab. ¡Puedes seguir extendiendo y ajustando el código para otros casos de uso!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
